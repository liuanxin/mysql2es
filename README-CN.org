
[[README.org][English Readme]] | 中文说明

** MariaDB/MySQL to Elasticsearch

  同步 MariaDB/MySQL 表的数据到 Elasticsearch, 支持添加和更新, 不支持物理删除(物理删除需要根据 binlog 才能处理),
  建议使用逻辑删除(业务系统使用逻辑删除本身就是一件很自然的事), 比如在表中添加 deleted(1 已删除, 默认是 0)字段.

  基于 jdk 8 和 spring boot 2, 支持 Elasticsearch 6.3.2

相关的配置如下:
#+BEGIN_SRC yml
spring:
  datasource:                   # mysql 配置见: org.springframework.boot.autoconfigure.jdbc.DataSourceProperties 和 com.zaxxer.hikari.HikariConfig
    ... 数据库配置 ...
  elasticsearch.rest:
    uris: 192.168.1.2:9200      # es 配置见: org.springframework.boot.autoconfigure.elasticsearch.rest.RestClientProperties

db2es:
  cron: 0/5 * * * * *           # 可以不设定, 默认是每分钟执行一次

  relation:
    -
      table: t_order            # *** 必须设定且要有主键. 主键会生成 es 中 /index/type/id 的 id, 如果是多列主键会用 "-" 拼接, 可以使用 % 做为通配来匹配多张表(当分表时)
      increment-column: id      # *** 必须设定. 表示用来做数据增量操作时用, 一般使用自增 id 或 time(更新时间戳)

      index: order              # 可以不设定. 表示 es 中 /index/type/id 的 index, 不设定将会从数据库表名生成(t_some_one ==> some-one), 6.0 开始 index name 必须是小写
      scheme: true              # 可以不设定. 是否在启动时基于 数据库表结构 生成 es 的 scheme, 默认是 false, 建议先在 es 中建立好索引的 scheme

      # 可以不设定. 自定义的 sql 语句(不要用 ORDER BY 和 LIMIT, 会基于 increment-column 自动添加), 不设定将会基于 table 来拼装
      sql: "select o.id, o.order_no, o.customer_code, o.order_status, ifnull(o.price,0) price, ifnull(o.sum,0) sum,
          o.create_time, unix_timestamp(o.update_time) update_time, ifnull(o.pay_time,0) pay_time,
          ifnull(o.ship_time,0) ship_time, ifnull(o.receipt_time,0) receipt_time, ifnull(o.success_time,0) success_time,
          oa.receiver, oa.province, oa.city, oa.area, oa.address, oa.phone
        from t_order o
          left join t_order_address oa on o.id = oa.order_id"
      table-alias: o            # 可以不设定. 如果 sql 有使用多个表 join, 主表的别名
      limit: 2000               # 可以不设定. 一次从数据库获取 及 同步进 es 的条数, 默认是 1000

      key-column: c1,c2         # 可以不设定. 用来生成 index 的 id 列, 不设置将会自动从表中获取, 当表中有主键又有多列唯一索引, 想用唯一索引来做 index 的 id 时可以使用此配置
      id-prefix:                # 可以不设定. 当想在 index 的 id 上加前缀时使用
      id-suffix:                # 可以不设定. 当想在 index 的 id 上加后缀时使用
      route-column: c1,c2       # 可以不设定. 数据保存进 es 时用来做分片的字段, 多个用逗号隔开
      pattern-to-id: false      # 可以不设定. true 表示将表名的通配数据做为 id 的一部分(比如上面的 table 使用 t_order_% 通配, 则表 t_order_2016 同步时 2016 将做为 id 的前缀), 默认是 true

      column-lower-camel: true  # 属性是否转为驼峰, true 则将表中的 user_name 转换成 userName, 默认是 false
      mapping:                  # 可以不设定. 默认将会从表字段生成, 只设置特殊情况即可
        c_type: type              # table column(如果有别名则使用别名) : es field
      ignore-column: c1,c2      # 可以不设定. 上面的 sql 中不想写入索引的字段(如果字段有别名则用别名)

      big-count-to-sql: 2000    # 可以不设定. sql 中 limit start,1000 里的 start 超出这个值就将 sql 优化成 inner join 的方式, 默认是 2000
      primary-key: id           # 可以不设定. 主键名, 当表数据很多时使用  LIMIT 1000万,1000  效率会很慢, 这个字段会优化 sql 语句, 默认是 id
      # 原来的 sql: SELECT ... FROM t_product WHERE time > '2010-01-01 00:00:01' LIMIT 1000万,1000
      # 优化的 sql: SELECT ... FROM t_product c inner join (SELECT id FROM t_product WHERE time > '2010-01-01 00:00:01' LIMIT 1000万,1000) t on t.id = c.id
      # 原先的 sql 执行时先通过索引找到 id, 再去存数据的物理块取记录, 最后在结果集里偏移 1000万 后再取 1000 条, 所以效率好不了
      # 优化的 sql 括号中偏移 1000万 是基于覆盖索引在处理(索引存的是索引列 + 主键), 然后再用 id 联表取数据, 因此这样是很快的

      nested-mapping:
        # 如果有 t_order 和 t_order_item 表, t_order 主键是 id, t_order_item 关联字段是 order_id, 则 main-field 是 id, nested-field 是 order_id
        item:
          main-field: id
          sql: SELECT sku_id, name, unit_price, num, total FROM t_order_item
          nested-field: order_id
    -
      table: t_product
      increment-column: update_time
#+END_SRC


es 索引相关的 scheme 示例如下
#+BEGIN_SRC yml
DELETE /order
PUT /order
{
  "settings": {
    "number_of_shards": "5",
    "number_of_replicas": "0"
  },
  "mappings": {
    "properties": {
      "id": {
        "type": "long"
      },
      "order_no": {
        "type": "keyword"
      },
      "customer_code": {
        "type": "keyword"
      },
      "order_status": {
        "type": "integer"
      },
      "price": {
        "type": "scaled_float",
        "scaling_factor": 100
      },
      "sum": {
        "type": "integer"
      },
      "create_time": {
        "type": "date",
        "format": "epoch_millis||yyyy-MM-dd||yyyy-MM-dd HH:mm:ss||yyyy-MM-dd HH:mm:ss SSS"
      },
      "update_time": {
        "type": "date",
        "format": "epoch_millis||yyyy-MM-dd||yyyy-MM-dd HH:mm:ss||yyyy-MM-dd HH:mm:ss SSS"
      },
      "pay_time": {
        "type": "date",
        "format": "epoch_millis||yyyy-MM-dd||yyyy-MM-dd HH:mm:ss||yyyy-MM-dd HH:mm:ss SSS"
      },
      "ship_time": {
        "type": "date",
        "format": "epoch_millis||yyyy-MM-dd||yyyy-MM-dd HH:mm:ss||yyyy-MM-dd HH:mm:ss SSS"
      },
      "receipt_time": {
        "type": "date",
        "format": "epoch_millis||yyyy-MM-dd||yyyy-MM-dd HH:mm:ss||yyyy-MM-dd HH:mm:ss SSS"
      },
      "success_time": {
        "type": "date",
        "format": "epoch_millis||yyyy-MM-dd||yyyy-MM-dd HH:mm:ss||yyyy-MM-dd HH:mm:ss SSS"
      },

      "receiver": {
        "type": "keyword"
      },
      "province": {
        "type": "keyword"
      },
      "city": {
        "type": "keyword"
      },
      "area": {
        "type": "keyword"
      },
      "address": {
        "type": "keyword"
      },
      "phone": {
        "type": "keyword"
      },

      "item": {
        "type": "nested",
        "properties": {
          "sku_id": {
            "type": "long"
          },
          "name": {
            "type": "keyword"
          },
          "unit_price": {
            "type": "scaled_float",
            "scaling_factor": 100
          },
          "num": {
            "type": "integer"
          },
          "total": {
            "type": "scaled_float",
            "scaling_factor": 100
          }
        }
      }
    }
  }
}
#+END_SRC


cron 的说明如下
#+BEGIN_EXAMPLE
.------------------- second (0 - 59)   if (0/10) then (0, 10, 20, 30, 40, 50) run
.  .---------------- minute (0 - 59)
.  .  .------------- hour (0 - 23)
.  .  .  .---------- day of month (1 - 31)
.  .  .  .  .------- month (1 - 12)   OR jan,feb,mar,apr,may,jun,jul,aug,sep,oct,nov,dec
.  .  .  .  .  .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat
.  .  .  .  .  .
?  *  *  *  *  *

如  0/5 * * * * *  表示每 5 秒运行一次
#+END_EXAMPLE


** 运行
#+BEGIN_SRC bash
git clone https://github.com/liuanxin/mysql2es.git
cd mysql2es
mvn clean package -DskipTests

# 更改 application-prod.yml 成你自己的配置
nohup java -jar -Dspring.profiles.active=prod target/mysql2es.jar >/dev/null 2>&1 &

或者

# 添加你的配置文件到任意地方, 如: ~/application.yml(建议基于 application-prod.yml 修改即可)
nohup java -jar -Dspring.config.location=~/application.yml target/mysql2es.jar >/dev/null 2>&1 &


# 日志在 ~/logs/mysql2es.log 中
#+END_SRC


** 说明

建议先在 Elasticsearch 中建好 index 的 scheme(如果想基于数据库表字段类型来生成可以在配置中设置 ~scheme~ 为 ~true~).  \\

系统启动后会根据定时规则来同步数据, 同步时基于 sql 拼接增量字段来获取分页数据并批量写入 Elasticsearch 直到没有数据为止,
最后的记录会存到临时文件供下次同步时会用到(如果到了下次运行时间, 但上次还没有运行结束将会顺延).

PS:  \\
如果数据量很大, 第一次同步会耗费一点时间. 调整 *limit* 的值可以提升同步速度.
临时文件会每个索引生成一个, 比如有 ~product~ 和 ~order~ 这样两个索引, 会生成两个临时文件 ~/tmp/product~ 和 ~/tmp/order~,
windows 在 ~C:\Users\current_user\AppData\Local\Temp~ 目录下, 可以在运行的命令行加上 ~-Djava.io.tmpdir=/path/to/tmpdir~ 来修改,
如果将索引对应的临时文件手动删除, 下一次同步时此索引将会进行全量操作.
